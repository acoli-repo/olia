---
layout: base
title:  'Tokenization'
permalink: fr/overview/tokenization.html
---

# Tokenization

The French tokenization follows the universal guidelines: contractions are undone (e.g., _au_ becomes two tokens _Ã  le_). Otherwise the tokenization is based on white spaces and punctuations (except for multiword expressions with hyphens which are not split, e.g., _Etats-Unis_ "United States", _sous-marin_ "submarine" stay one token).
